{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbe4353-ae93-4f8c-b244-5f5488134979",
   "metadata": {},
   "source": [
    "# Google Top Stories - An exploration\n",
    "\n",
    "**Description:** This dataset was collected during the pandemic, it contains headlines shown by Google Search.\n",
    "It is organized by year, month, date, hour, in a series of nested folders. The leaf folders contain JSON files with information about Google's top stories. \n",
    "\n",
    "Your goal is to write first a Python function that takes the name of the folder \"GoogleTopStories\" and stores the content of all the JSON files into a single CSV file. Once you have a CSV file, you can practice your pandas & seaborn skills in analyzing the data.\n",
    "\n",
    "Some tips and ideas for analysis:\n",
    "1. Use the Python command `os.walk` to iteratively traverse the nested subfolders. Account for hidden files that start with .\n",
    "2. Although the dataset has a column domain, imagine that it doesn't have it and write a function that takes a URL and extracts the domain name from it and saves it in a column. Use the `.apply` method to create the column. Learn how to parse URLs with `urllib.parse`.\n",
    "3. Create a bar chart with the frequencies of the top 10 domains. (Use domains, since 'source name' contains duplicates.)\n",
    "4. Create a heatmap that shows the distribution of domains across the 'story_position' values.\n",
    "5. Create timeseries of unique articles per month by query type. (This is challenging, because it is not using pandas' timeseries.)\n",
    "\n",
    "\n",
    "**Table of Content [Solutions]**\n",
    "1. [Reading all JSON files](#sec1)\n",
    "2. [Creating a new column](#sec2)\n",
    "3. [Bar chart of top domains](#sec3)\n",
    "4. [Heatmap for the story positions](#sec4)\n",
    "5. [Timeseries of unique articles by query](#sec5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b059e-6191-40d4-9dad-6e75a306c4e0",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## Part 1: Reading all JSON files\n",
    "\n",
    "Spend some time looking at the structure of the folders and subfolders in GoogleTopStories. You should notice the deep nesting. The function `os.walk` recursively traverses this nested structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd93b62-65e6-41e1-b7d2-fa9bfbf517bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, csv\n",
    "\n",
    "def writeFilesToCSV(pathName):\n",
    "    \"\"\"\n",
    "    Takes a foldername as an argument. Recursively reads all JSON files \n",
    "    and saves their content into a list. At the end, saves all data into a CSV file.\n",
    "    \"\"\"\n",
    "    allTopStories = []\n",
    "    totalFiles = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(pathName):\n",
    "        for fN in filenames: \n",
    "            if fN.endswith('.json'): # Avoid any other types of files, such as .DS_Store\n",
    "                totalFiles += 1\n",
    "                filePath = os.path.join(dirpath, fN) # create the whole path of a file\n",
    "                with open(filePath) as inputF:\n",
    "                    data = json.load(inputF)\n",
    "                    allTopStories.extend(data)\n",
    "                \n",
    "    print(\"Total number of JSON files:\", totalFiles)\n",
    "    print(\"Total number of Top stories in the files:\", len(allTopStories))\n",
    "\n",
    "    with open(\"our-results.csv\", \"w\") as fout:\n",
    "        header = list(allTopStories[0].keys()) + ['category'] # Notice this, because not all top stories have a \"category\"\n",
    "        dW = csv.DictWriter(fout, fieldnames=header)\n",
    "        dW.writeheader()\n",
    "        dW.writerows(allTopStories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619fa6ab-c350-4a08-acc6-97d1b46c617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for our folder\n",
    "writeFilesToCSV('GoogleTopStories')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c6ad8-a092-4a40-80b1-bb2f35761927",
   "metadata": {},
   "source": [
    "**Your task: Explore how `os.walk` works**\n",
    "\n",
    "In order to see how os.walks works, use below the for loop from the function to only explore the month of Aprill 2020, by printing out what the for loop generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c6bed-a359-4b5f-ad51-275179db5230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e8127-1cdd-4c18-a552-e645e4eb2456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2ff2670-3681-494f-980b-12006e8c039c",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## Part 2: Create the new `domain` column\n",
    "\n",
    "Let's load the data that we created in Part 1 into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3509da0-2b9c-4e7b-bdca-5c1e7c26415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('our-results.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74609d1-b6a6-4db7-b2ed-51c4c0369603",
   "metadata": {},
   "source": [
    "**How to extract the domain name from the URL?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47127e98-2197-419a-a588-07d4458e1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "oneUrl = df.iloc[0]['url'] # retrieve url from first row of dataframe\n",
    "urlparse(oneUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dea6541-41b4-4291-9d12-d3aaba37daeb",
   "metadata": {},
   "source": [
    "Notice that the result is an object and the domain name is the value of the attribute `netloc`. Now, we can easily make use of this to write the helper function to extract the domain name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d615da2-047c-4f56-aff8-584cba379dea",
   "metadata": {},
   "source": [
    "**Write a helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76741dae-c2cd-4a56-8a9c-5c4e964b1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def getDomain(field):\n",
    "    \"\"\"returns the domain name of a url\"\"\"\n",
    "    return urlparse(field).netloc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209dd761-07d9-4ab8-8291-2e48be3b6a4b",
   "metadata": {},
   "source": [
    "Apply the helper function to the whole column and store the results to a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955a6bb-bf25-4543-8bc5-2649c578927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['domain2'] = df['url'].apply(getDomain)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eec9de3-9458-4b8f-b2d9-8580b2b39029",
   "metadata": {},
   "source": [
    "**Your Task: Create a new column**\n",
    "\n",
    "Create a new column that will store the number of words on the title of each article. The column name should be `wordCount`. Show the head of the dataframe to indicate that the column was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7458a-b4ed-4f3d-976f-055cd0d0f542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de352e08-9a19-499e-b0b0-3ef590f69155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "deb72a7a-6e81-4171-b0ea-ace861271d8f",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## Part 3: Bar chart of top 10 domains\n",
    "\n",
    "To create the bar chart of the top 10 domains, we first need to find the top 10 domains.\n",
    "\n",
    "The method `value_counts` returns a **sorted** series of counts for each value in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4c45f-c7e5-4137-a3b2-c7e9de8cb8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 domains using value_counts\n",
    "domainCounts = df['domain'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca24649-ede3-44fd-bf47-562f31c0bbf3",
   "metadata": {},
   "source": [
    "Let's see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d7eaa-c881-4257-aee4-b84a9ef34952",
   "metadata": {},
   "outputs": [],
   "source": [
    "domainCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb485b-4935-44da-b4bf-5e5c7b618460",
   "metadata": {},
   "source": [
    "Let's look up the type of our our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c5af3-9cb6-4d80-b310-68bba8e0d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(domainCounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9758c-5ff7-4c45-b5dc-921e3787f129",
   "metadata": {},
   "source": [
    "Since the result is a Series, we will convert it to a dataframe. [**Note:** The method `reset_index` converts a Series into a DataFrame, where the original index becomes a column in the DataFrame, and the Series values occupies another column, for which we have to provide a column name.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446a56b-49d3-4ee9-aa3c-7b049a7bc8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = domainCounts.reset_index(name='count')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d2b4c-8874-4f38-ad7e-49703f777cf5",
   "metadata": {},
   "source": [
    "Now that we have a dataframe we can use Seaborn to generate charts. Below I'm creating a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79831878-17d2-4c07-bfbc-965757b44a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 4))   # adjusting the size of the figure where the plot will be displayed\n",
    "sns.set_style(\"whitegrid\")  \n",
    "\n",
    "# Create the horizontal bar plot\n",
    "ax = sns.barplot(x='count', y='domain', data=data, color=\"salmon\", legend=None)\n",
    "\n",
    "# Set titles\n",
    "ax.set_xlabel(\"Count\", fontsize=10)\n",
    "ax.set_ylabel(\"Domain\", fontsize=10)\n",
    "ax.set_title(\"Top 10 Domains by Count\", fontsize=14)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1576471-b181-4d79-9651-3bf5d8178476",
   "metadata": {},
   "source": [
    "**Your Task: Create a bar chart of query occurrences**\n",
    "\n",
    "Adapt the code above to generate the bar chart of the query occurrences. Make sure that you change the barplot titles to reflect the new variable being displayed. Change the color of the graph and [visit this Seaborn documentation page](https://seaborn.pydata.org/tutorial/aesthetics.html) for inspiration on changing the style of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24e808-f9a7-47cb-8a74-63ee6e298aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee7935-5305-4e18-8013-43c11a034899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77dc99af-71f7-42a4-8085-8f07c92f569f",
   "metadata": {},
   "source": [
    "<a id=\"sec4\"></a>\n",
    "## Part 4: Heatmap for the story positions\n",
    "\n",
    "We are interested in the question: Are all news sources equally likely to show up in all positions? Or some of them show up more frequently in a certain position? To explore this question visually, we will create a heatmap. However, since there are hundreds of news sources in our dataset, we will focus only on the top 10 for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16365311-07f9-407a-b2ed-9dad0990cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, find the names of the top 10 domains\n",
    "# Then, filter the dataframe to select only the rows of one of the top 10 domains (articles that belong to these news domains)\n",
    "\n",
    "topTen = df['domain'].value_counts()[:10].index.tolist() # remember from part 3 that value_counts returns a Series and the 'domain' column is the index of it\n",
    "dfSmall = df[df['domain'].isin(topTen)] # do the filtering. Notice the filter syntax.\n",
    "dfSmall.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8ed4ea-b290-42a6-ac43-fa047424f17c",
   "metadata": {},
   "source": [
    "As a reminder, here is what the size of the whole dataframe is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106088f6-0377-4c20-b125-548008176957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e398e80a-70df-4dff-b435-0ed9331005f6",
   "metadata": {},
   "source": [
    "Let's calcuate the proportion of articles from the top 10 domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f25f95-3ef7-416a-a8ba-644a7232e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = dfSmall.shape[0]/df.shape[0] * 100\n",
    "proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e41c91a-edd9-42b4-9d20-8af50df60a0d",
   "metadata": {},
   "source": [
    "**Question:** What does the fact that the proportion of the occurrences of the top 10 domains comes at 45% tell us about Google's algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf7d37-fd2f-4e75-a54d-a396b1442a73",
   "metadata": {},
   "source": [
    "**Your Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c0a4a-ad73-4378-b60c-0de298f090c4",
   "metadata": {},
   "source": [
    "### Creating a pivot table\n",
    "\n",
    "Our current dataframe, `dfSmall` presents itself as a **tidy table**, each row is an observation. We will now convert it to a form that it is not a **tidy table**, because the columns will become values of the variable \"story_position\". This will allow us to count how many domains show up in each of the 10 positions.\n",
    "\n",
    "To create such a table we will use pandas' `pivot_table` method, which builds upon the `groupby` method that we have seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0385ae-39bf-4ac2-82c9-67f05cdc6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create the pivot table to count each domain occurrence by position\n",
    "\n",
    "dfFinal = dfSmall[['domain', 'story_position']] # work with a two-column dataframe\n",
    "\n",
    "pivotDF = dfFinal.pivot_table(index='domain', columns='story_position', \n",
    "                              aggfunc='size',fill_value=0)\n",
    "pivotDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327276f-9197-4a53-ae8a-1351a646a499",
   "metadata": {},
   "source": [
    "Now that we have a dataframe, let's normalize the rows by dividing each cell in a column by the sum of values of that row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb6b82-65e2-481f-ac04-33b767c97815",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = pivotDF.div(pivotDF.sum(axis=1), # first generate the sum of values in each row\n",
    "                         axis=0) # then divide all cells in a colum, by the corresponding sum\n",
    "normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6bea3-8dcf-4a2d-99f9-ec4ce0b35001",
   "metadata": {},
   "source": [
    "Now that the data is ready, we can create the heatmap, providing some additional instructions to make it look good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214926a7-9164-4808-aa9d-632f9723e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.set(font_scale=1.2)  # Adjust font size\n",
    "sns.heatmap(normalized, \n",
    "            cmap='BuGn', # set color map Blue to Green\n",
    "            annot=False, # do not show the numerical values in each cell\n",
    "            linewidths=0.5) # width of lines that separate the cells in the map\n",
    "\n",
    "# We are directly setting the properties of the current axes, without explicitely referring to it as we did in the barplot image\n",
    "plt.xlabel('Story position', fontsize=10)\n",
    "plt.ylabel('Domain', fontsize=10)\n",
    "plt.title('Proportion of Top 10 Domains by Position', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aad6c1-5394-4fa1-aa01-10f4589db1c5",
   "metadata": {},
   "source": [
    "**Questions:** Given this visualization, how can we answer our starting question: Are all news sources equally likely to show up in all positions?  \n",
    "Furthermore, what does this tell us about Google's algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978a2bb-4d91-408b-91b0-0c6ef252b606",
   "metadata": {},
   "source": [
    "**Your Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3606f9e-bbdd-427a-9311-a67a058b337f",
   "metadata": {},
   "source": [
    "<a id=\"sec5\"></a>\n",
    "## 5. Timeseries of monthly unique articles organized by query type\n",
    "\n",
    "From prior experience in working with Google Top Stories data, I know that some articles show up multiple times during the day or over a few days. We can verify this through code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7a83e-d36e-4200-89e1-5a3f4a2adf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.url.unique().size == df.url.size # compare sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b8758-a119-4fa2-b8d1-9f6ecb746e5d",
   "metadata": {},
   "source": [
    "Print the sizes to compare unique url to the total urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0066478-be70-4613-a834-1f12d6dfc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique: {df.url.unique().size}, Total: {df.url.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec291001-f705-4115-9dcd-bc2d3c74674b",
   "metadata": {},
   "source": [
    "**Your Task: Domains and Sources**  \n",
    "Throughout the notebook, we worked with the domain column, instead of source. \n",
    "1. Check if these two columns have the same size in terms of unique values.\n",
    "2. What is the size of unique values for each of them?\n",
    "3. Speculate about the reason for the divergence between the two columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc79a0a6-e402-496e-8399-fdafd2eb9da9",
   "metadata": {},
   "source": [
    "**Your exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c997916-d497-4cfd-be68-63d470ecc127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09fae5-300a-497f-9d30-494499604ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19540749-cd9c-4278-8c8f-99d1ca80de35",
   "metadata": {},
   "source": [
    "### Focus on unique articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c4f648-ae3c-4dfe-a8e9-b27ec555d75d",
   "metadata": {},
   "source": [
    "Let's start by dropping all the rows that have repeating URLs, however, we will first sort the rows, so that they are in the order of publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7212ea-8bef-493f-b2be-cd44df5b0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['date'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2446cc-6943-4f29-9e32-3d23809a1108",
   "metadata": {},
   "source": [
    "We can see from the indices (they don't start at 0 any longer) that the rows were sorted. Let's drop the duplicate URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f859e80-489f-4a83-abf6-67328e087a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUnique = df.drop_duplicates(subset=['url']) \n",
    "dfUnique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279a44b-7932-4985-9657-0aab7f265e43",
   "metadata": {},
   "source": [
    "I will create a new column, year-month, since the date field is too granular. [**Note**: Read more about this at the end of the notebook.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf2590-90ef-42f3-b01c-3356aa0342bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDate(row):\n",
    "    \"\"\"return a date in the format YYYY-MM\"\"\"\n",
    "    return row['date'][:7] \n",
    "\n",
    "dfUnique['year-month'] = dfUnique.apply(splitDate, axis=1)\n",
    "dfUnique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713f273-1709-47d9-89a0-f79267b64eaa",
   "metadata": {},
   "source": [
    "**Important Note:** When running the cell above, some of you might have received the following warning:  \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "\n",
    "When we run the statement `dfUnique = df.drop_duplicates(subset=['url'])` we intended to create a new dataframe. However, pandas warns us because it can't guarantee that dfUnique isn't sharing data with df under the hood due to its optimizations. The longer explanation is that pandas sometimes uses views internally to optimize memory usage. When we perform an operation that could be ambiguous, such as modifying a DataFrame that could potentially be a view of another DataFrame, pandas issues a warning.\n",
    "\n",
    "If we don't want the warning to show, we should explicitely tell pandas make a new copy:\n",
    "\n",
    "`dfUnique = df.drop_duplicates(subset=['url']).copy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffef6f-19bf-4c70-bd42-fb70b99ff4fa",
   "metadata": {},
   "source": [
    "### Pivot Table: counting articles per query\n",
    "\n",
    "Now that each row has a month value, we can create a pivot table to count how many time a query showed in each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5087619-e887-4a74-aabf-a49466b87390",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMonthDF = dfUnique.pivot_table(index=\"query\", \n",
    "                                    columns=\"year-month\", \n",
    "                                    aggfunc=\"size\", \n",
    "                                    fill_value=0)\n",
    "queryMonthDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb12338-b7e2-4520-bbf0-c90d7299774b",
   "metadata": {},
   "source": [
    "Let's validate that all articles are shown in this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaabb0e-cc69-43a8-8b6d-3f9e1b3102a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMonthDF.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e45c16-2902-4101-8cae-266681fde636",
   "metadata": {},
   "source": [
    "It's looks right!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387669c-97c7-4c51-ac20-5b1118631179",
   "metadata": {},
   "source": [
    "### Generate the time series plot\n",
    "\n",
    "There are many ways to create a time series plot. Because I gave you this task before you had seen pandas timeseries, below I will show how to create the plot using linebars. There are two ways to do this.\n",
    "\n",
    "**Soution 1: Plot line bars with a for loop**\n",
    "\n",
    "Because the table we created above is a pivot table, also known as a \"wide table\" (different from the \"tidy table\"), seaborn doesn't know how to work with it directly, so we have to generate each line within a for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea12fd-70e5-425e-bc9f-12d490b19552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Iterate over each row to plot\n",
    "for index, row in queryMonthDF.iterrows():\n",
    "    sns.lineplot(x=queryMonthDF.columns,  # the year-month values\n",
    "                 y=row.values,  # the counts for each query\n",
    "                 label=index, # this will be the query values\n",
    "                 lw=3)\n",
    "\n",
    "# Change the parameters of the current axes (plot) to deal with the font size\n",
    "plt.xticks(rotation=45) # Rotate dates\n",
    "plt.ylabel('Article count', fontsize=10)\n",
    "plt.xlabel('Year-Month', fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title('Number of unique articles by query', fontsize=12)\n",
    "plt.legend(title='Query', fontsize=10, loc=\"upper right\", title_fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935dc1a-8d8d-456c-ac48-25dd323ea2d8",
   "metadata": {},
   "source": [
    "**Solution 2: Wide table vs. long table**\n",
    "\n",
    "We mentioned that the `pivot_table` method creates a **wide format table**. Seaborn prefers to work with a **long format table** (we called it the tidy data).  \n",
    "Thus, we will convert the wide table to a long table.\n",
    "\n",
    "First, let's look again at our wide-format table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f13166-94bf-4ebe-b22b-8bda6bd5fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryMonthDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f922d-02de-43bc-9244-d79b827d5245",
   "metadata": {},
   "source": [
    "Notice that the first column, query, is also serving as an index column. Eventually, what we want is to **unpivot** this table and create a table that looks like this:\n",
    "\n",
    "```\n",
    "query year-month count\n",
    "Anthony Fauci 2020-04 0\n",
    "Anthony Fauci 2020-05 175\n",
    "Anthony Fauci 2020-06 304\n",
    "...\n",
    "Covid-19 2020-04 102\n",
    "Covid-19 2020-04 531\n",
    "...\n",
    "```\n",
    "\n",
    "That is from a table that now has 11 colums x 5 rows, we want a table with 3 columns and 55 rows (from wide to long).\n",
    "\n",
    "The method `melt` below will perform this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4cf817-b71b-46c7-9d71-a46517a588ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLongTab = queryMonthDF.reset_index().melt(id_vars='query',  # column that remains an \"identifier\" column, will not be melted\n",
    "                                          var_name='year-month', # name for variable column created after the melting (this contains names of melted columns)\n",
    "                                          value_name='count') # column created after melting (contains values of melted columns)\n",
    "dfLongTab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026ecd2-ba54-4d99-a608-b8c0d815b536",
   "metadata": {},
   "source": [
    "Let's check the shape of the created dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d308b1-9724-40a8-8df6-70dccd73f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLongTab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf1b20-51d5-4550-afad-f4ffdc3065b1",
   "metadata": {},
   "source": [
    "It's exactly what we expected!\n",
    "\n",
    "Now that we have the data in the desired format, we can do the plotting without having to use a for loop to iterate through the lines, seaborn will do that itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821448c-01c1-4d5f-afd9-3cb6e1db2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "sns.lineplot(data=dfLongTab, \n",
    "             x='year-month', \n",
    "             y='count', \n",
    "             hue='query', lw=3)\n",
    "\n",
    "# Change the parameters of the current axes (plot) to deal with the font size\n",
    "plt.xticks(rotation=45) # Rotate dates\n",
    "plt.ylabel('Article count', fontsize=10)\n",
    "plt.xlabel('Year-Month', fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.title('Number of unique articles by query', fontsize=12)\n",
    "plt.legend(title='Query', fontsize=10, loc=\"upper right\", title_fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db950fe-1854-4f94-83bf-747206660c77",
   "metadata": {},
   "source": [
    "Notice that we produced the same graph but with two different starting dataframes and code for generating the lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b252265-29f9-4d94-8be1-531000074e95",
   "metadata": {},
   "source": [
    "**Your Task: Plot each month**\n",
    "\n",
    "Using the code above, create two functions:\n",
    "1. Create a function that given a year-month value, for example: \"2020-05\", prepares the dataframe that contains the \"month-day\" counts of the unique articles for each query.\n",
    "2. Create a function that can take the output from point 1) and plot the lineplot.\n",
    "\n",
    "Excecute these functions for at least two dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3747600-a7d3-4fd3-a69e-a39406d77ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
