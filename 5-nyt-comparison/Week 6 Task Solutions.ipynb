{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644e74d1-7750-4f87-9758-b2a4d369ddd9",
   "metadata": {},
   "source": [
    "# Week 6 Tasks: NYT API Data and Cosine Similarity for Text \n",
    "\n",
    "These tasks were discussed during week 6 and you had to work on them with your group.  \n",
    "Below are the solutions and additional tasks that will be helpful for your project.\n",
    "\n",
    "**Table of Content**\n",
    "* [Part 1: Working with the NYT API](#sec1)\n",
    "* [Part 2: Cosine Similarity for Text](#sec2)\n",
    "* [Part 3: Similarity of Spring and Summer sentences](#sec3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47288b9e-1d91-4df6-8c98-01d8082c6172",
   "metadata": {},
   "source": [
    "<a id=\"sec1\"></a>\n",
    "## Part 1: Working with the NYT API \n",
    "\n",
    "We have the following goals:\n",
    "\n",
    "1. Use the API to get all articles from a month\n",
    "2. Verify the number of articles\n",
    "3. Find the distribution of articles by section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed5235f-e011-42c5-afcd-4678c615fcf1",
   "metadata": {},
   "source": [
    "### Important: replace the string below with your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eded646-a519-4488-9efb-dd5e68c1d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "myAPIkey = \"bPv2NYsDnFkDWUxGACZUWFPKqzktIx5l\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d637cf-7eac-45b1-b6c9-a3c28dd06813",
   "metadata": {},
   "source": [
    "We will write a function that given a date (month and year) will talk to the NYT API and get the articles for that time period. We will store the results in a JSON file to process when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "977e6acc-2c29-43ec-8f9a-99de35b5eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "def getNYTArticles(year, month, apiKey):\n",
    "    \"\"\"Function that sends a request to the NYT API for all articles in a month\n",
    "    and then stores the results in a JSON file.\n",
    "    \"\"\"\n",
    "    # create URL\n",
    "    URL = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={apiKey}\"\n",
    "\n",
    "    # send the request to get the data\n",
    "    data = requests.get(URL)\n",
    "    if data.status_code == 200:\n",
    "        print(\"Successfully got the data.\")\n",
    "\n",
    "    dataJson = data.json() # get response as JSON\n",
    "\n",
    "    with open(f\"NYT_{year}-{month}.json\", 'w') as fout:\n",
    "        json.dump(dataJson, fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5a98c-0641-4336-8d34-35c626579eab",
   "metadata": {},
   "source": [
    "Let's test the function for the months of February 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef9ff83-df33-4037-ad86-b029bd53116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully got the data.\n"
     ]
    }
   ],
   "source": [
    "getNYTArticles(2024, 2, myAPIkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1d927-2713-4a74-9d2d-05cfde14e136",
   "metadata": {},
   "source": [
    "## Explore the NYT Data\n",
    "\n",
    "Now that we have the data, we will look into how to retrieve things like article title, section, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d2c5c4-696d-4518-a513-443d3db5fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"NYT_2024-2.json\") as fin:\n",
    "    articles = json.load(fin)\n",
    "\n",
    "print(type(articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe47492-d11a-45d4-b1a9-3ebf1aeed9cf",
   "metadata": {},
   "source": [
    "We can check the keys of this dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32c6639-9d09-47e0-8299-b1733379e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['copyright', 'response'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9414a10a-b15a-44b4-805f-70877b0f6c3f",
   "metadata": {},
   "source": [
    "Then we check what values are stored under each key, without printing the values, but checking for their type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c542d6-248d-40aa-a580-443f4b68aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyright <class 'str'>\n",
      "response <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for key in articles:\n",
    "    print(key, type(articles[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "133b5d15-0bac-47c0-8acd-57a4e3d0f659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Copyright (c) 2024 The New York Times Company. All Rights Reserved.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['copyright']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7ac7a-003a-4413-ad3d-aaaa4f893c24",
   "metadata": {},
   "source": [
    "Let's look at the keys for 'response':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f21c0e-0fd0-45b1-b80b-d82cd6672472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['docs', 'meta'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['response'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d43299-30db-404b-a80d-1ed2c75fc453",
   "metadata": {},
   "source": [
    "One more time, we look what kind of information is stored under each of these keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8affb171-a949-4507-928d-bde3c03ca065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs <class 'list'>\n",
      "meta <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for key in articles['response']:\n",
    "    print(key, type(articles['response'][key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13648859-3869-4274-98ca-4ed39e8ebc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hits': 3791}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is under the \"meta\" key?\n",
    "\n",
    "articles['response']['meta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac6aee-0f8a-4ac2-a51d-eb57cad8664d",
   "metadata": {},
   "source": [
    "So, this shows how many articles are in the data. We can verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22f30f73-eb9e-4865-801d-54fb7452eba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3791"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles['response']['docs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b437bb-dc0d-4162-8369-ce547030d873",
   "metadata": {},
   "source": [
    "It's the same number, which is a good thing. Now let's look at what one of the articles (or docs) looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "085e6715-f6ec-4d9a-bdd6-23cb86fee3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'Periods of backlash take shape after surges of Black progress. We have entered another such period.',\n",
       " 'web_url': 'https://www.nytimes.com/2024/01/31/opinion/racist-backlash-history.html',\n",
       " 'snippet': 'Periods of backlash take shape after surges of Black progress. We have entered another such period.',\n",
       " 'lead_paragraph': 'I am fascinated, and alarmed, by the swiftness with which periods of backlash take shape after surges of Black progress, and I believe that we have entered another such period.',\n",
       " 'print_section': 'A',\n",
       " 'print_page': '21',\n",
       " 'source': 'The New York Times',\n",
       " 'multimedia': [{'rank': 0,\n",
       "   'subtype': 'xlarge',\n",
       "   'caption': None,\n",
       "   'credit': None,\n",
       "   'type': 'image',\n",
       "   'url': 'images/2024/02/01/multimedia/31blow1-hvfq/31blow1-hvfq-articleLarge.jpg',\n",
       "   'height': 800,\n",
       "   'width': 600,\n",
       "   'subType': 'xlarge',\n",
       "   'crop_name': 'articleLarge',\n",
       "   'legacy': {'xlarge': 'images/2024/02/01/multimedia/31blow1-hvfq/31blow1-hvfq-articleLarge.jpg',\n",
       "    'xlargewidth': 600,\n",
       "    'xlargeheight': 800}},\n",
       "  {'rank': 0,\n",
       "   'subtype': 'jumbo',\n",
       "   'caption': None,\n",
       "   'credit': None,\n",
       "   'type': 'image',\n",
       "   'url': 'images/2024/02/01/multimedia/31blow1-hvfq/31blow1-hvfq-jumbo.jpg',\n",
       "   'height': 1024,\n",
       "   'width': 768,\n",
       "   'subType': 'jumbo',\n",
       "   'crop_name': 'jumbo',\n",
       "   'legacy': {}},\n",
       "  {'rank': 0,\n",
       "   'subtype': 'superJumbo',\n",
       "   'caption': None,\n",
       "   'credit': None,\n",
       "   'type': 'image',\n",
       "   'url': 'images/2024/02/01/multimedia/31blow1-hvfq/31blow1-hvfq-superJumbo.jpg',\n",
       "   'height': 2048,\n",
       "   'width': 1536,\n",
       "   'subType': 'superJumbo',\n",
       "   'crop_name': 'superJumbo',\n",
       "   'legacy': {}},\n",
       "  {'rank': 0,\n",
       "   'subtype': 'thumbnail',\n",
       "   'caption': None,\n",
       "   'credit': None,\n",
       "   'type': 'image',\n",
       "   'url': 'images/2024/02/01/multimedia/31blow1-hvfq/31blow1-hvfq-thumbStandard.jpg',\n",
       "   'height': 75,\n",
       "   'width': 75,\n",
       "   'subType': 'thumbnail',\n",
       "   'crop_name': 'thumbStandard',\n",
       "   'legacy': {'thumbnail': 'images/2024/02/01/multimedia/31blow1-hvfq/31blow1-hvfq-thumbStandard.jpg',\n",
       "    'thumbnailwidth': 75,\n",
       "    'thumbnailheight': 75}},\n",
       "  {'rank': 0,\n",
       "   'subtype': 'thumbLarge',\n",
       "   'caption': None,\n",
       "   'credit': None,\n",
       "   'type': 'image',\n",
       "   'url': 'images/2024/02/01/multimedia/31blow1-hvfq/31blow1-hvfq-thumbLarge.jpg',\n",
       "   'height': 150,\n",
       "   'width': 150,\n",
       "   'subType': 'thumbLarge',\n",
       "   'crop_name': 'thumbLarge',\n",
       "   'legacy': {}}],\n",
       " 'headline': {'main': 'The Dawn of a New Era of Oppression',\n",
       "  'kicker': 'Charles M. Blow',\n",
       "  'content_kicker': None,\n",
       "  'print_headline': 'The Dawn of a New Era of Oppression',\n",
       "  'name': None,\n",
       "  'seo': None,\n",
       "  'sub': None},\n",
       " 'keywords': [{'name': 'subject',\n",
       "   'value': 'Hate Crimes',\n",
       "   'rank': 1,\n",
       "   'major': 'N'},\n",
       "  {'name': 'subject', 'value': 'Black People', 'rank': 2, 'major': 'N'},\n",
       "  {'name': 'subject', 'value': 'Blacks', 'rank': 3, 'major': 'N'},\n",
       "  {'name': 'subject', 'value': 'Discrimination', 'rank': 4, 'major': 'N'},\n",
       "  {'name': 'subject',\n",
       "   'value': 'Civil Rights Movement (1954-68)',\n",
       "   'rank': 5,\n",
       "   'major': 'N'},\n",
       "  {'name': 'subject', 'value': 'Reconstruction Era', 'rank': 6, 'major': 'N'},\n",
       "  {'name': 'subject',\n",
       "   'value': 'Segregation and Desegregation',\n",
       "   'rank': 7,\n",
       "   'major': 'N'},\n",
       "  {'name': 'persons',\n",
       "   'value': 'Nixon, Richard Milhous',\n",
       "   'rank': 8,\n",
       "   'major': 'N'}],\n",
       " 'pub_date': '2024-02-01T00:00:08+0000',\n",
       " 'document_type': 'article',\n",
       " 'news_desk': 'OpEd',\n",
       " 'section_name': 'Opinion',\n",
       " 'byline': {'original': 'By Charles M. Blow',\n",
       "  'person': [{'firstname': 'Charles',\n",
       "    'middlename': None,\n",
       "    'lastname': '',\n",
       "    'qualifier': None,\n",
       "    'title': None,\n",
       "    'role': 'reported',\n",
       "    'organization': '',\n",
       "    'rank': 1}],\n",
       "  'organization': None},\n",
       " 'type_of_material': 'Op-Ed',\n",
       " '_id': 'nyt://article/f2a4bafd-6333-5aee-8bd7-08fa9572ec5e',\n",
       " 'word_count': 928,\n",
       " 'uri': 'nyt://article/f2a4bafd-6333-5aee-8bd7-08fa9572ec5e'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['response']['docs'][0] # using indexing, because we know that the data is stored in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50978e8-b3aa-41c5-b549-4b4f99941214",
   "metadata": {},
   "source": [
    "We can see tha an article is a somewhat nested data structure, it's a dictionary, but many of the keys point to list of other dictionaries. Let's look at the top fields: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48c0c987-974d-4e76-aa5e-afb05fa33ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract <class 'str'>\n",
      "web_url <class 'str'>\n",
      "snippet <class 'str'>\n",
      "lead_paragraph <class 'str'>\n",
      "print_section <class 'str'>\n",
      "print_page <class 'str'>\n",
      "source <class 'str'>\n",
      "multimedia <class 'list'>\n",
      "headline <class 'dict'>\n",
      "keywords <class 'list'>\n",
      "pub_date <class 'str'>\n",
      "document_type <class 'str'>\n",
      "news_desk <class 'str'>\n",
      "section_name <class 'str'>\n",
      "byline <class 'dict'>\n",
      "type_of_material <class 'str'>\n",
      "_id <class 'str'>\n",
      "word_count <class 'int'>\n",
      "uri <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "oneArticle = articles['response']['docs'][0]\n",
    "for key in oneArticle:\n",
    "    print(key, type(oneArticle[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b592b8b-165c-4e35-904a-43df39750b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-01T00:00:08+0000'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneArticle['pub_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cc50e07-7964-4234-ab70-afd94e2eea2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'subject', 'value': 'Hate Crimes', 'rank': 1, 'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Black People', 'rank': 2, 'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Blacks', 'rank': 3, 'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Discrimination', 'rank': 4, 'major': 'N'},\n",
       " {'name': 'subject',\n",
       "  'value': 'Civil Rights Movement (1954-68)',\n",
       "  'rank': 5,\n",
       "  'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Reconstruction Era', 'rank': 6, 'major': 'N'},\n",
       " {'name': 'subject',\n",
       "  'value': 'Segregation and Desegregation',\n",
       "  'rank': 7,\n",
       "  'major': 'N'},\n",
       " {'name': 'persons',\n",
       "  'value': 'Nixon, Richard Milhous',\n",
       "  'rank': 8,\n",
       "  'major': 'N'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneArticle['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc22ee-0748-4850-bc23-272d0dbc6340",
   "metadata": {},
   "source": [
    "### Find the distribution of articles by section\n",
    "\n",
    "As we saw above, every article has a section name, so we can easily collect all those names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0f050-8a06-45a6-b33d-b6b2a485abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = [article['section_name'] for article in articles['response']['docs']]\n",
    "\n",
    "# Let's look up a few of them\n",
    "sections[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890db0b-3c4f-46a1-8338-b31a4cf4acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "distDct = Counter(sections) # count the occurrences of each section name\n",
    "\n",
    "distDct.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383daa6-b200-45dd-a49f-fdf15f040518",
   "metadata": {},
   "source": [
    "## Tasks for you:\n",
    "\n",
    "1. Write a Python function that takes a date, for example, \"2024-02-12\", and returns the list of articles for that day.\n",
    "2. Write some code that explores whether the fields \"abstract\" and \"snippet\" are always the same or they differ. Which one has more information?\n",
    "3. Write a function that given one article (in its nested structure), creates a flat dictionary with keys that are relevant for analysis: either the abstract or snippet (see point 2); lead paragraph; headline; keywords concatenated via semicolon; pub_date; document_type; section_name; and type_of_material\n",
    "4. Write another function that calls the function from point 3 on every article, to create a list of article dictionaries, and convert this list into a dataframe and then store it as a CSV file with the date-month in the title (this is important for point 5 below).\n",
    "5. Once you have done all of these in the notebook, create a Python script that can be called with a date (from a TikTok video). First, the script looks whether a CSV with cleaned articles is in our folder. If not, calls first the API function to get the articles and then the function that converts them into a CSV. Then, it loads the CSV into a datafram and it uses filtering to get the articles for the desired date. These articles will be used for the Semantic Similarity portion of the TikTok Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cb2581b-de88-4e84-8a1c-cb0287025661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArticlesOfDay(date):\n",
    "    year = int(date[:4])\n",
    "    print(year)\n",
    "    month = int(date[5:7]) if date[5] == '0' else int(date[5:7])\n",
    "    print(month)\n",
    "    getNYTArticles(year, month, myAPIkey)\n",
    "\n",
    "    with open(f\"NYT_{year}-{month}.json\") as fin:\n",
    "        data = json.load(fin)\n",
    "\n",
    "    articles = data['response']['docs']\n",
    "\n",
    "    articles_day = []\n",
    "    for article in articles:\n",
    "        if article['pub_date'][:10] == date:\n",
    "            articles_day.append(article)\n",
    "    return articles_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e6a68c4-e845-4fae-b891-43d64ebb1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n",
      "2\n",
      "Successfully got the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = getArticlesOfDay(\"2024-02-12\")\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39131ae8-2057-4b7b-b5f8-651904d91f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Cetaphil commercial showed a father and daughter connecting over football and the music superstar. But a social media influencer said the idea was stolen from her.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9219f52-ce30-4cd2-8842-bd443576fe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Cetaphil commercial showed a father and daughter connecting over football and the music superstar. But a social media influencer said the idea was stolen from her.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48a01bf7-6151-481e-95e0-2c6a86d4f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: Have you ever baked a giant chocolate chip cookie in a skillet? If you haven’t, now is the time because Samantha Seneviratne’s recipe is utterly magical. Like everything she puts forth, Samantha’s giant cookie is perfectly balanced, a harmony of brown sugar, walnuts and chocolate chips seasoned with just enough salt to tame the sweetness. And smushing one giant cookie into a skillet is vastly easier and faster than forming individual cookies. It’s the kind of after-work treat that makes Monday altogether worth it. \n",
      "\n",
      "Snippet:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in result:\n",
    "    if article['abstract'] != article['snippet']:\n",
    "        print(\"Abstract:\", article['abstract'],\"\\n\")\n",
    "        print(\"Snippet:\", article['snippet'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "becc8360-8add-4d33-a0f3-bd934446c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenArticle(article):\n",
    "    output_dict = {}\n",
    "    things_to_get = ['abstract', 'lead_paragraph', 'headline', 'keywords', 'pub_date', 'document_type', 'section_name']\n",
    "    for info in things_to_get:\n",
    "        output_dict[info] = article[info]\n",
    "    keywords = output_dict['keywords']\n",
    "    keywords = [tag['value'] for tag in keywords] \n",
    "    output_dict['keywords'] = keywords\n",
    "    return output_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87eefb83-ee41-4a0f-9414-5cf29059f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'A Cetaphil commercial showed a father and daughter connecting over football and the music superstar. But a social media influencer said the idea was stolen from her.',\n",
       " 'lead_paragraph': 'When an advertisement for Cetaphil lotion was released online days before the Super Bowl, it drew rave reviews for a narrative that evoked a familiar story for parents, football fans and followers of Taylor Swift.',\n",
       " 'headline': {'main': 'Ad Nods to Taylor Swift and Football, Drawing Cheers and Criticism',\n",
       "  'kicker': None,\n",
       "  'content_kicker': None,\n",
       "  'print_headline': '',\n",
       "  'name': None,\n",
       "  'seo': None,\n",
       "  'sub': None},\n",
       " 'keywords': ['Advertising and Marketing',\n",
       "  'Super Bowl',\n",
       "  'Cosmetics and Toiletries',\n",
       "  'Swift, Taylor',\n",
       "  'Kelce, Travis',\n",
       "  'Social Media',\n",
       "  'TikTok (ByteDance)'],\n",
       " 'pub_date': '2024-02-12T00:30:32+0000',\n",
       " 'document_type': 'article',\n",
       " 'section_name': 'Business Day'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattenArticle(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c3977fc-8669-46ea-a1cd-cefbf2542102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def flattenAllArticles(date):\n",
    "    articles_of_the_day = getArticlesOfDay(date)\n",
    "    output_list = []\n",
    "    for article in articles_of_the_day:\n",
    "        output_list.append(flattenArticle(article))\n",
    "    \n",
    "    df = pd.DataFrame(output_list)\n",
    "    file_name = f\"articles_{date[:7]}.csv\"\n",
    "    df.to_csv(file_name, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2336e17-1a79-42ba-b3d4-f511c89bd4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n",
      "2\n",
      "Successfully got the data.\n"
     ]
    }
   ],
   "source": [
    "all_articles_list = flattenAllArticles(\"2024-02-12\") ## change the parameter to work with actual dataset. result is just everything on 2024-2-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75924973-17da-4821-b233-b4c54d949b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>document_type</th>\n",
       "      <th>section_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Cetaphil commercial showed a father and daug...</td>\n",
       "      <td>When an advertisement for Cetaphil lotion was ...</td>\n",
       "      <td>{'main': 'Ad Nods to Taylor Swift and Football...</td>\n",
       "      <td>[Advertising and Marketing, Super Bowl, Cosmet...</td>\n",
       "      <td>2024-02-12T00:30:32+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Business Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift and Travis Kelce have been the su...</td>\n",
       "      <td>Extending a weekslong right-wing meltdown over...</td>\n",
       "      <td>{'main': 'Trump Says It Would Be ‘Disloyal’ fo...</td>\n",
       "      <td>[Swift, Taylor, Kelce, Travis, Trump, Donald J...</td>\n",
       "      <td>2024-02-12T00:32:24+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In a halftime set that touched on more than a ...</td>\n",
       "      <td>A few minutes into Usher’s dynamic and sly Sup...</td>\n",
       "      <td>{'main': 'Usher Brings Precise Details to Pop’...</td>\n",
       "      <td>[Rap and Hip-Hop, Super Bowl, Usher, Keys, Ali...</td>\n",
       "      <td>2024-02-12T02:14:00+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pop superstar used a Verizon ad to tell fa...</td>\n",
       "      <td>After days of speculation and online sleuthing...</td>\n",
       "      <td>{'main': 'Beyoncé Announces New Album in Super...</td>\n",
       "      <td>[Pop and Rock Music, Super Bowl, Knowles, Beyo...</td>\n",
       "      <td>2024-02-12T02:41:56+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Albert Haynes Jr., 70, went by “Billy ...</td>\n",
       "      <td>William Albert “Billy Jack” Haynes Jr., who in...</td>\n",
       "      <td>{'main': 'Former W.W.F. Wrestler Arrested in W...</td>\n",
       "      <td>[Murders, Attempted Murders and Homicides, Wre...</td>\n",
       "      <td>2024-02-12T03:10:32+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Pregnant women with diabetes or high blood pre...</td>\n",
       "      <td>Women who develop high blood pressure or diabe...</td>\n",
       "      <td>{'main': 'Children Born to Mothers With Pregna...</td>\n",
       "      <td>[your-feed-science, Pregnancy and Childbirth, ...</td>\n",
       "      <td>2024-02-12T23:13:06+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>The shooting took place at the Mount Eden Aven...</td>\n",
       "      <td>A 35-year-old man was killed and five other pe...</td>\n",
       "      <td>{'main': 'One Killed and 5 Wounded in Shooting...</td>\n",
       "      <td>[Subways, Murders, Attempted Murders and Homic...</td>\n",
       "      <td>2024-02-12T23:13:38+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Our guide to the themes dominating the race.</td>\n",
       "      <td>The special election in New York’s Third Congr...</td>\n",
       "      <td>{'main': 'How Special Is New York’s Special El...</td>\n",
       "      <td>[Politics and Government, Elections, Suozzi, T...</td>\n",
       "      <td>2024-02-12T23:20:47+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>The former president showed up at the federal ...</td>\n",
       "      <td>Former President Donald J. Trump and his lawye...</td>\n",
       "      <td>{'main': 'Trump Attends Court Hearing on Acces...</td>\n",
       "      <td>[Federal Criminal Case Against Trump (Document...</td>\n",
       "      <td>2024-02-12T23:31:02+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>After months of treading lightly about the for...</td>\n",
       "      <td>Nikki Haley, in the final stretch before the S...</td>\n",
       "      <td>{'main': 'Defending Troops, Haley Says Golf Co...</td>\n",
       "      <td>[Haley, Nikki R, Trump, Donald J, Republican P...</td>\n",
       "      <td>2024-02-12T23:31:55+0000</td>\n",
       "      <td>article</td>\n",
       "      <td>U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              abstract  \\\n",
       "0    A Cetaphil commercial showed a father and daug...   \n",
       "1    Taylor Swift and Travis Kelce have been the su...   \n",
       "2    In a halftime set that touched on more than a ...   \n",
       "3    The pop superstar used a Verizon ad to tell fa...   \n",
       "4    William Albert Haynes Jr., 70, went by “Billy ...   \n",
       "..                                                 ...   \n",
       "111  Pregnant women with diabetes or high blood pre...   \n",
       "112  The shooting took place at the Mount Eden Aven...   \n",
       "113       Our guide to the themes dominating the race.   \n",
       "114  The former president showed up at the federal ...   \n",
       "115  After months of treading lightly about the for...   \n",
       "\n",
       "                                        lead_paragraph  \\\n",
       "0    When an advertisement for Cetaphil lotion was ...   \n",
       "1    Extending a weekslong right-wing meltdown over...   \n",
       "2    A few minutes into Usher’s dynamic and sly Sup...   \n",
       "3    After days of speculation and online sleuthing...   \n",
       "4    William Albert “Billy Jack” Haynes Jr., who in...   \n",
       "..                                                 ...   \n",
       "111  Women who develop high blood pressure or diabe...   \n",
       "112  A 35-year-old man was killed and five other pe...   \n",
       "113  The special election in New York’s Third Congr...   \n",
       "114  Former President Donald J. Trump and his lawye...   \n",
       "115  Nikki Haley, in the final stretch before the S...   \n",
       "\n",
       "                                              headline  \\\n",
       "0    {'main': 'Ad Nods to Taylor Swift and Football...   \n",
       "1    {'main': 'Trump Says It Would Be ‘Disloyal’ fo...   \n",
       "2    {'main': 'Usher Brings Precise Details to Pop’...   \n",
       "3    {'main': 'Beyoncé Announces New Album in Super...   \n",
       "4    {'main': 'Former W.W.F. Wrestler Arrested in W...   \n",
       "..                                                 ...   \n",
       "111  {'main': 'Children Born to Mothers With Pregna...   \n",
       "112  {'main': 'One Killed and 5 Wounded in Shooting...   \n",
       "113  {'main': 'How Special Is New York’s Special El...   \n",
       "114  {'main': 'Trump Attends Court Hearing on Acces...   \n",
       "115  {'main': 'Defending Troops, Haley Says Golf Co...   \n",
       "\n",
       "                                              keywords  \\\n",
       "0    [Advertising and Marketing, Super Bowl, Cosmet...   \n",
       "1    [Swift, Taylor, Kelce, Travis, Trump, Donald J...   \n",
       "2    [Rap and Hip-Hop, Super Bowl, Usher, Keys, Ali...   \n",
       "3    [Pop and Rock Music, Super Bowl, Knowles, Beyo...   \n",
       "4    [Murders, Attempted Murders and Homicides, Wre...   \n",
       "..                                                 ...   \n",
       "111  [your-feed-science, Pregnancy and Childbirth, ...   \n",
       "112  [Subways, Murders, Attempted Murders and Homic...   \n",
       "113  [Politics and Government, Elections, Suozzi, T...   \n",
       "114  [Federal Criminal Case Against Trump (Document...   \n",
       "115  [Haley, Nikki R, Trump, Donald J, Republican P...   \n",
       "\n",
       "                     pub_date document_type  section_name  \n",
       "0    2024-02-12T00:30:32+0000       article  Business Day  \n",
       "1    2024-02-12T00:32:24+0000       article          U.S.  \n",
       "2    2024-02-12T02:14:00+0000       article          Arts  \n",
       "3    2024-02-12T02:41:56+0000       article          Arts  \n",
       "4    2024-02-12T03:10:32+0000       article          Arts  \n",
       "..                        ...           ...           ...  \n",
       "111  2024-02-12T23:13:06+0000       article        Health  \n",
       "112  2024-02-12T23:13:38+0000       article      New York  \n",
       "113  2024-02-12T23:20:47+0000       article          U.S.  \n",
       "114  2024-02-12T23:31:02+0000       article          U.S.  \n",
       "115  2024-02-12T23:31:55+0000       article          U.S.  \n",
       "\n",
       "[116 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061baf0d-6c54-457b-b3d7-aecd0fd29b10",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## Part 2: Cosine Similarity for Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ba378-a8b9-44c2-806c-d46672d67d12",
   "metadata": {},
   "source": [
    "We will start with the example that was in the slides. There, we initially used the Jaccard similarity to rank sentences most similar to a query, and when that didn't work as expected, we looked at the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02ccfc-4467-4bc5-9361-6e934c24c4dc",
   "metadata": {},
   "source": [
    "### Use Jaccard similarity for a query phrase and a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2df6d-775c-4c58-b3d4-d72ae5ee94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"red dress\"\n",
    "\n",
    "sentences = [\n",
    "\"she wore a dress and red earrings\",\n",
    "\"the dress has a red wine stain\",\n",
    "\"tomorrow I will wear my new red dress\",\n",
    "\"the red dress in the photo resembles the red dress she is wearing\",\n",
    "\"short dress\",\n",
    "\"red lipstick\"\n",
    "]\n",
    "\n",
    "def jaccard(text1, text2):\n",
    "    \"\"\"Implement Jaccard similarity. Assumes there is no punctuation in text.\"\"\"\n",
    "    sw1 = set(text1.lower().split()) # turn into a set of words\n",
    "    sw2 = set(text2.lower().split())\n",
    "    sim = len(sw1.intersection(sw2)) / len(sw1.union(sw2))\n",
    "    return round(sim, 4) # round to 4 digits after the comma\n",
    "\n",
    "def applyJaccard(query, sentences):\n",
    "    \"\"\"Appl the Jaccard similarity between query and each sentence\"\"\"\n",
    "    results = []\n",
    "    for sent in sentences:\n",
    "        jac = jaccard(query, sent)\n",
    "        results.append((jac, sent))\n",
    "    \n",
    "        # Sort in descending order\n",
    "        results.sort(reverse=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "# call the function\n",
    "\n",
    "applyJaccard(q, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a902535-3e2f-40cb-b1e1-83f12d9cfbdd",
   "metadata": {},
   "source": [
    "As we discussed in class, the Jaccard similarity is not doing well with our data (showing as similar text that, thus, we will try the cosine similarity. However, in order to apply the cosine similarity, we need some other steps:\n",
    "\n",
    "1. Create the vocabulary of words that will serve as the dimensions of our vector space\n",
    "2. Represent each document as a vector in the vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b7baa-d3e9-4ab5-936b-d157ceb4ecaa",
   "metadata": {},
   "source": [
    "### Create Vocabulary\n",
    "\n",
    "While our sentences in the example don't have punctuation, most of the time text will have it, thus, we need to be prepared to remove it. This will be necesary in order to avoid a word show multiple times, with and without punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eada87-b484-4ff6-86ae-8e3da3b44f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"that, that is the thing I want: dancing by the river! ah, the river, I have missed it so much!\"\n",
    "phrase.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10a224-8a04-4cf6-902f-5be5bc39acbc",
   "metadata": {},
   "source": [
    "Notice how we have both \"that!\" and \"that\", and also \"river,\" and \"river!\". This is why we will remove punctuation. Luckily, Python has a library that lists all punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a24b4-dbed-47a5-aef3-6932ae997af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721a72c-0d0a-4b72-9dfc-da57935f5cd4",
   "metadata": {},
   "source": [
    "One way to go about it is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbb783-deea-4385-8133-3ba596115a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(char for char in phrase if char not in string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3885419-d1b4-470f-b877-7b352eb43522",
   "metadata": {},
   "source": [
    "Notice how all the punctuation is gone. Now that we know how to do this, we can write our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b23d86-8bd4-48a6-96b8-5acea2294f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabulary(textchunk):\n",
    "    \"\"\"Given some text, create the vocabulary of unique words.\"\"\"\n",
    "    textchunk = textchunk.lower()\n",
    "    cleantext = \"\".join(char for char in textchunk if char not in string.punctuation)\n",
    "    words = set(cleantext.split())\n",
    "    voc = sorted(words)\n",
    "\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec90fd-b1d9-41b5-bf1d-b0ff75d8576c",
   "metadata": {},
   "source": [
    "Let's test it with our sentences. Since they are a list, we turn them into a string first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8530bd-7e6c-423b-a6c1-9d8a5a3d3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "getVocabulary(\" \".join(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570aa541-20e6-4649-a072-e7747c8c0e7c",
   "metadata": {},
   "source": [
    "It looks good, no word is repeated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b4d6b-ed75-46dd-8eb7-cdc086929acb",
   "metadata": {},
   "source": [
    "### Vector representation\n",
    "\n",
    "Now that we have a vocabulary, we can easily convert every sentence into a vector of numbers. Remember, all the vectors will have the same length. They will have 0 for a dimension (word) that they don't have, and the count of word for a dimension they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df263f81-89fe-43e0-b8c2-c3a7389cbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vector(sentence, voc):\n",
    "    \"\"\"Given a sentence and the vocabulary for the problem,\n",
    "    turn every sentence into a vector.\n",
    "    \"\"\"\n",
    "    cleantext = \"\".join(char for char in sentence if char not in string.punctuation)\n",
    "    words = cleantext.lower().split()\n",
    "    vector = [words.count(w) for w in voc]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373e862-7388-441f-be8c-df4858a5049d",
   "metadata": {},
   "source": [
    "Let's try it with one sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41a829-15bb-4cfb-87b6-71fe59f1eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = getVocabulary(\" \".join(sentences))\n",
    "text2vector(sentences[0], voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3160b6-9859-4232-9633-8c7c9d1554df",
   "metadata": {},
   "source": [
    "Let's verify that this is done right by checking what sentence was turned into a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0bd5c3-d39d-45df-b299-d68985f95e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283598ad-4b39-4971-8678-07e9e58a5fe8",
   "metadata": {},
   "source": [
    "Let's combine the vocabulary and the vector to see the pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07681d03-9145-4d0d-bc62-35d8e7d08091",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(voc, text2vector(sentences[0], voc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044674c-702e-41cd-acf7-a256ad70319b",
   "metadata": {},
   "source": [
    "Notice how each word in our sentence has a 1 next to it and all the other words have a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324cbe7f-5532-4400-9072-e5be860c9c29",
   "metadata": {},
   "source": [
    "We will now convert all the sentences to vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f4537-e117-4a85-9abc-9f7d5a0f232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2vec = [text2vector(sent, voc) for sent in sentences]\n",
    "sent2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d6ada-dfdd-46c2-819c-78eeef345a0c",
   "metadata": {},
   "source": [
    "We represent this in pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80266fcd-74f1-425c-b9f7-7d5cf5e2fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(sent2vec, \n",
    "                  columns=voc,\n",
    "                  index=[f\"doc_{i+1}\" for i in range(len(sentences))])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb0b24-529d-4729-9536-07133eed7954",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "We discussed the implementation of cosine similarity in class. Below is the function that implements it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56ea1c-ad57-4932-897f-853683b8dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    "def cosineSimilarity(vec1, vec2):\n",
    "    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n",
    "    V1 = np.array(vec1)\n",
    "    V2 = np.array(vec2)\n",
    "    cosine = np.dot(V1, V2)/(norm(V1)*norm(V2))\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d180583c-772e-417d-9bb3-5a757cd4b02a",
   "metadata": {},
   "source": [
    "Now that we have the cosine similarity function, we will write a function that given a query and a list of sentences, calculates the similarity score for each pair (query, sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84fcec-d7b6-4778-b325-f71186be5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankDocuments(query, sentences):\n",
    "    \"\"\"Given a query and some sentences, rank the sentences for \n",
    "    which are the most similar to the query.\n",
    "    \"\"\"\n",
    "    # Step 1: create vocabulary\n",
    "    voc = getVocabulary(\" \".join(sentences))\n",
    "\n",
    "    # Step 2: generate vector for query\n",
    "    queryVec = text2vector(query, voc)\n",
    "\n",
    "    # Step 3: generate vector for sentences and calculate cosine similarity at once\n",
    "    similarities = []\n",
    "    for sent in sentences:\n",
    "        sentVec = text2vector(sent, voc)\n",
    "        sim = cosineSimilarity(queryVec, sentVec)\n",
    "        similarities.append((round(sim, 4), sent)) # keep track of sentences\n",
    "\n",
    "    similarities.sort(reverse=True) # most similar sentence at the top\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34727669-66b5-457a-bd42-179a69b7e0dd",
   "metadata": {},
   "source": [
    "Now we can call the function for our query \"red dress\" and the list of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2c623-8e46-41c2-a5c8-44f16ef214a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankDocuments(\"red dress\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f57d06-5e24-499b-ba9d-71206812ee93",
   "metadata": {},
   "source": [
    "**Note:** These values are slightly different from the ones in the slides. There was a bug with the word \"I\", which was not lowercased in the sentences, so it didn't count in the vector. The bug has been fixed in this version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31052f-a095-4a3b-963d-93ea3d8aa447",
   "metadata": {},
   "source": [
    "<a id=\"sec3\"></a>\n",
    "## Part 3: Similarity of Spring and Summer sentences\n",
    "\n",
    "You were given the following sentences in the slides of Day 10. These were created by GenAI to capture the spirit of \"spring\" and \"summer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac7add-0cab-4e15-8c8c-670a22bd24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "springSentences = [\n",
    "\"As spring unfolds, the warmth of the season encourages the first blossoms to open, signaling longer days ahead.\",\n",
    "\"Spring brings not only blooming flowers but also the anticipation of sunny days and outdoor activities.\",\n",
    "\"With the arrival of spring, people begin planning their summer vacations, eager to enjoy the seasonal warmth.\",\n",
    "\"The mild spring weather marks the transition from the cold winter to the inviting warmth of summer.\",\n",
    "\"During spring, families often start spending more time outdoors, enjoying the season's pleasant temperatures and the promise of summer fun.\"\n",
    "]\n",
    "\n",
    "summerSentences = [\n",
    "\"Summer continues the season's trend of growth and warmth, with gardens full of life and days filled with sunlight.\",\n",
    "\"The summer season is synonymous with outdoor adventures and enjoying the extended daylight hours that began in spring.\",\n",
    "\"As summer arrives, the warm weather invites a continuation of the outdoor activities that people began enjoying in spring.\",\n",
    "\"The transition into summer brings even warmer temperatures, allowing for beach visits and swimming, much awaited since the spring.\",\n",
    "\"Summer vacations are often planned as the days grow longer, a pattern that starts in the spring, culminating in peak summer leisure.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d7cfd-7d88-4ae0-a4d8-fd57d7abf98f",
   "metadata": {},
   "source": [
    "**Our Goal:**\n",
    "\n",
    "We want to generate a heatmap of the similarity scores between all sentences to one another to find out how similar they are. To achieve this goal, we need to break down the task:\n",
    "\n",
    "1. We need to create first the vocabulary of all terms (or the dimensions of our vector space).\n",
    "2. We will turn every sentence into a vector.\n",
    "3. We will compare every sentence to every other sentence through the cosine similartiy to create the similarity matrix.\n",
    "4. We will draw the heatmap with seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d4566-ff9e-440f-8270-28266576f1d4",
   "metadata": {},
   "source": [
    "### Create Vocabulary\n",
    "\n",
    "We will call the function `getVocabulary` that we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76cc83-44a6-483a-8b62-504aa457b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "allSentences = \" \".join(springSentences) + \" \" + \" \".join(summerSentences)\n",
    "voc = getVocabulary(allSentences)\n",
    "print(f\"Vocabulary has {len(voc)} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e8c8e-3ba6-4186-888c-419c40f4371d",
   "metadata": {},
   "source": [
    "### Convert sentences to vectors\n",
    "\n",
    "We will call the function `text2vector` on every sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cb611-dbc2-4758-949d-8106223faa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentVectors = [text2vector(sent, voc) for sent in springSentences+summerSentences]\n",
    "print(len(sentVectors), len(sentVectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c7b5a-af95-4c18-8055-2595ad5c325c",
   "metadata": {},
   "source": [
    "This means that we created 10 vectors, each with a length of 102 dimensions.  \n",
    "Let's check our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf70219-42ae-470d-a1ee-ed77b5f6df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneSent = springSentences[0]\n",
    "oneSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588ad7d-9c4f-4fb5-8c5b-92d9701e3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(zip(text2vector(oneSent, voc), voc))\n",
    "nonZero = [pair for pair in pairs if pair[0] != 0]\n",
    "nonZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0ed94-87d4-4709-ba59-9554e5ff6d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Words in sentence: {len(oneSent.split())}; nonzero terms in vector: {len(nonZero)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0a4c2-acfb-40d6-b15e-dda74d2f5f12",
   "metadata": {},
   "source": [
    "This looks good. There are 16 unique words, and the word \"the\" is repeated two more times, that explains the numbers 16 and 18. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c5533-86e8-4829-9de5-e3e8ac0d8cd0",
   "metadata": {},
   "source": [
    "### Calculating the similarity matrix\n",
    "\n",
    "We will calculate the cosine similarity for every pair of sentences. This makes sense because we only have 10 sentences, if we had way more, we will try to be more efficient and not repeat the calculations (since we know that the matrix is symmetrical). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b9b81-d5b1-43f2-b029-1b15a78014e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "simMatrix = []\n",
    "for vec1 in sentVectors:\n",
    "    simRow = []\n",
    "    for vec2 in sentVectors:\n",
    "        simRow.append(cosineSimilarity(vec1, vec2))\n",
    "    simMatrix.append(simRow)\n",
    "\n",
    "print(simMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee2c37-ac61-41de-be5c-1c4d0ed65905",
   "metadata": {},
   "source": [
    "### Generate the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15937a9a-5ed7-4f45-b2a9-8fa4d9b15f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def drawHeatmap(sentLabels, simMtrx, plotTitle):\n",
    "    \"\"\"Draws a heatmap for the similarity matrix.\n",
    "    \"\"\"\n",
    "    sns.set(font_scale=0.9)\n",
    "    g = sns.heatmap(\n",
    "          simMtrx, # similarity matrix with the cosine sim values\n",
    "          xticklabels=sentLabels,\n",
    "          yticklabels=sentLabels,\n",
    "          vmin=0,\n",
    "          vmax=1,\n",
    "          cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(sentLabels, rotation=90)\n",
    "    g.set_title(plotTitle, fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0d895-0cbc-46e0-abc4-039dac2e69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSent = [sent[:25] for sent in springSentences+summerSentences]\n",
    "drawHeatmap(shortSent, simMatrix, \"Cosine similarity matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb27fe5-0ad2-4e5d-b3ea-d50ae4d1fccb",
   "metadata": {},
   "source": [
    "### Short Exploration\n",
    "\n",
    "Let's look at the similarity matrix in a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a402d1-8fd8-439c-85b5-2ec2524cb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f\"s{i+1}\" for i in range(10)]\n",
    "df = pd.DataFrame(simMatrix, columns=labels, index=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db3f119-4464-43e2-ac5f-351e6526db01",
   "metadata": {},
   "source": [
    "I will write some code to compare sentences that have a high similarity score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081a313-7a0b-4504-9077-cc8af1d2d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWords(sent):\n",
    "    \"\"\"Get the words of a sentence after lowercasing and removing punctuation.\"\"\"\n",
    "    cleantext = \"\".join(char for char in sent.lower() if char not in string.punctuation)\n",
    "    cleanWords = cleantext.split()\n",
    "    return cleanWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca5258d-495a-4ba3-b498-65b080bcf912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareSentences(sent1, sent2):\n",
    "    \"\"\"Compare the content of two sentences.\"\"\"\n",
    "    words1 = getWords(sent1)\n",
    "    words2 = getWords(sent2)\n",
    "    commonWords = sorted([w for w in words1 if w in words2])\n",
    "    print(\"COMPARISON RESULTS\")\n",
    "    print(\"Sent1: \", sent1)\n",
    "    print(\"Sent2: \", sent2)\n",
    "    print(f\"Lengths of sentences: {len(words1)} and {len(words2)}. Words in common: {len(commonWords)}\")\n",
    "    print(\"Common words:\", commonWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021a92a-4bb4-4fc8-8689-4b13e9f31307",
   "metadata": {},
   "source": [
    "Let's check s1 and s4, in the group os Spring sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31164c1-f33b-4be3-a43b-ec5eb5c2bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareSentences(springSentences[0], springSentences[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fab4a1-d4f6-4572-bc2d-23814324f8c1",
   "metadata": {},
   "source": [
    "What about the sentences s7 and s8, in the group of Summer sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7e464-6db4-4e99-9b17-77b911ffb9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareSentences(summerSentences[1], summerSentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6a16c-48d8-48ab-bfd2-eeadbaf356ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
